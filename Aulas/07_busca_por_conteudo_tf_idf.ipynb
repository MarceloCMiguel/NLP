{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF e busca por conteúdo\n",
    "\n",
    "Nesta atividade, vamos lidar com a seguinte situação: temos um grande banco de dados com textos, e queremos encontrar qual texto é mais relevante para uma consulta. Esse problema aparece em buscadores como Google, e também em sistemas locais como ElasticSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Title  \\\n",
      "14935               Goya's Ghosts   \n",
      "1663           Cockeyed Cavaliers   \n",
      "33248                 Kids Return   \n",
      "13552              Speedway Junky   \n",
      "15298  Normal Adolescent Behavior   \n",
      "\n",
      "                                                    Plot  \n",
      "14935  In 1792, Spain reels amid the turmoil and uphe...  \n",
      "1663   In medieval England, Bert and his friend, Bob ...  \n",
      "33248  The movie is about two high school dropouts, M...  \n",
      "13552  The film stars Jesse Bradford as Johnny, a you...  \n",
      "15298  Wendy, Billie, and Ann are seniors at an alter...   1000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DATASET = 'datasets/wikipedia_movies.zip'\n",
    "df = pd.read_csv(DATASET).sample(1000)\n",
    "df = df[['Title', 'Plot']]\n",
    "print(df.head(), len(df))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 1\n",
    "**Objetivo: lembrar-se do que é TF e o que é DF**\n",
    "\n",
    "Identifique o Term Frequency e o Document Frequency nas asserções abaixo:\n",
    "\n",
    "1. Quanto maior o ___, mais comum é a palavra entre os documentos de uma coleção\n",
    "1. Quanto maior o ___, mais vezes a palavra é mencionada num documento específico\n",
    "1. $P(w | \\text{documento})$\n",
    "1. $P(w | \\text{coleção})$\n",
    "1. Ajuda a identificar a coleção da qual um documento faz parte\n",
    "1. Ajuda a identificar um documento dentro de uma coleção"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 2\n",
    "**Objetivo: refletir sobre o uso de TF-IDF**\n",
    "\n",
    "A medida TFIDF diz o quão relevante um documento é dentro de uma coleção e em relação a uma palavra específica. Ela é calculada para um par palavra-documento como:\n",
    "\n",
    "$\\text{TFIDF = TF / DF}$\n",
    "\n",
    "Quando um documento tem um TFIDF alto em relação a uma palavra, isso significa que:\n",
    "\n",
    "1. A palavra tende a ser (comum / incomum)\n",
    "1. O documento menciona a palavras (muitas / poucas) vezes\n",
    "\n",
    "Portanto, qual seria uma maneira de escrever um documento que tem intencionalmente um TFIDF alto para uma palavra?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 3\n",
    "**Objetivo: calcular TFIDF para documentos usando sklearn**\n",
    "\n",
    "TFIDF pode ser entendido como um processo de vetorização, semelhante a usar o CountVectorizer. Abaixo, há um código que mostra um exemplo dessa vetorização usando sklearn. \n",
    "\n",
    "1. Escolhendo um filme aleatório da coleção que carregamos, identifique o TFIDF das palavras \"zombie\", \"fungus\" e \"survival\".\n",
    "1. Identifique o filme que tem o maior TFIDF para a palavra \"zombie\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf = vectorizer.fit_transform(df['Plot'])\n",
    "\n",
    "j = vectorizer.vocabulary_['test']\n",
    "print(tfidf[2,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a random movie\n",
    "i = np.random.randint(0, len(df))\n",
    "random_movie = df.iloc[i]['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# for this random_movie, get the tfidf value for the word 'test'\n",
    "zombie_vocabulary = vectorizer.vocabulary_['zombie']\n",
    "# fungus_vocabulary = vectorizer.vocabulary_['fungus']\n",
    "survival_vocabulary = vectorizer.vocabulary_['survival']\n",
    "print(tfidf[i,zombie_vocabulary])\n",
    "# print(tfidf[i,fungus_vocabulary])\n",
    "print(tfidf[i,survival_vocabulary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# for this random movie, get the tfidf of the word 'test'\n",
    "j = vectorizer.vocabulary_['test']\n",
    "print(tfidf[i,j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "tfidf:  0.16149123461212997\n",
      "Warm Bodies\n"
     ]
    }
   ],
   "source": [
    "# to the word Zombie, get the movie that has the highest tfidf\n",
    "j = vectorizer.vocabulary_['zombie']\n",
    "m = tfidf[:,j].argmax()\n",
    "print(tfidf[:,j].toarray().argmax())\n",
    "print(\"tfidf: \", tfidf[m,j])\n",
    "print(df.iloc[tfidf[:,j].toarray().argmax()]['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Title                                               Plot\n",
      "10954  Flesheater  The film starts with a group of kids taking a ...\n"
     ]
    }
   ],
   "source": [
    "# get the row number of Fleshheater\n",
    "print(df[df['Title'] == 'Flesheater'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The film starts with a group of kids taking a hayride in the country on Halloween. They pay the local farmer to take them to a secluded area of the forest. The kids arrive and begin drinking, telling the farmer to come back after dark to pick them up. As the party wears on the group separates to find their own little love nests.\n",
      "Meanwhile, the farmer has stumbled across a large tree stump which he proceeds to remove with the help of his tractor. Under the stump is a large wooden box with an ancient seal telling not to break open the box. The farmer breaks the seal and opens the box. Inside is the Bill Heinzman \"Flesheater\" who precedes to eat the farmer making him a zombie in the process. Both zombies head towards where the kids are.\n",
      "Two of the kids who retreated to the barn for some alone time are killed by the flesheaters. As the flesh-eater is killing the kids, two of their friends walk in and see what's happening then they run outside to warn the group at the party. Inside the barn the kids who were attacked become zombies and head out of the barn for fresh victims back near the party and one of the girls is attacked in the woods by the zombies. It tears a chunk of shoulder away but the girl is saved by her boyfriend who hears her screams and tackles the flesh-eater.\n",
      "The remaining kids retreat to the old \"Spencers Farm\" a dis-used farmhouse in the woods. They proceed to nail up the windows and doors. They manage to phone the police but the call is cut short when a zombie outside rips the phone line out.\n",
      "Meanwhile, the two kids who escaped from the barn have caught up with the group (who refuse to open the doors in case of an attack) so the two kids hide in the basement and lock the door. Upstairs the girl bitten on the shoulder dies and returns as a zombie. Just as she gets up the zombies outside break in and the remaining group are slaughtered, each becoming a zombie and heading into the woods for more victims.\n",
      "A police car then turns up at Spencer's farm responding to the cut-short phone call. The police officer is attacked by a group of zombies and left for dead. The kids in the basement open the door and see the body of the policeman. They take his gun and kill his half remaining zombie corpse and escape into the night.\n",
      "Some of the zombies find their way to a residential street where they proceed to eat a local family inside their home turning them into zombies in the process. The two kids find a local stable where they try to warn the owner about the coming attack. He goes inside the house to find that his wife has become a zombie. More zombies appear and the man is cornered and eaten alive and the kids flee again.\n",
      "They find a large barn where a Halloween party is being held. The kids try to warn the group about the undead but they laugh it off as Halloween nonsense. Soon the zombies arrive and slaughter the party-goers. The two kids who survived the basement find a hiding spot inside the framework of the barn.\n",
      "Back in town, the police department are assembling a posse after hearing of the officer who was killed at Spencer's farm. As daylight approaches the posse have arrived at the woods. They find zombies emerging from the woods and proceed to kill the creatures. They proceed through the woodland killing zombies as they go. The posse arrive at the barn and find the party-goers are all zombies. The posse kill them as the zombie group come out of the barn. The two kids hiding in the barn hear the gunshots and think they are saved. They exit the barn and are shot on sight by a sniper (the same actor who shoots Ben in Night of the living dead).\n",
      "The posse throws all the bodies inside the barn and barricade it shut. They set it on fire burning the remaining few zombies inside. The posse thinking they destroyed all the zombies head home. A few days later a police officer is checking out the remains of the barn when he is attacked by the original flesheater, who kills him and begins the outbreak over again.\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[tfidf[:,j].toarray().argmax()]['Plot'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 4\n",
    "**Objetivo: implementar uma busca por vários termos simultaneamente**\n",
    "\n",
    "Uma possível maneira de implementar uma busca por vários termos é somar o TFIDF de todas as palavras da query para cada documento da coleção, e então retornar o documento que tem a maior soma. Por exemplo, numa busca por \"zombie fungus survival\" deveríamos somar, para cada documento, o TFIDF de \"zombie\", de \"fungus\" e de \"survival\" e então ordenar o resultado.\n",
    "\n",
    "1. Escreva código que implemente uma busca na base de dados de filmes à partir de uma query específica.\n",
    "1. Qual é a complexidade ($O(...)$) da sua busca?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "860\n",
      "tfidf:  [[0.22600513]]\n",
      "Killing 'em Softly\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "query = \"love robot\"\n",
    "\n",
    "# Implemente sua solução aqui\n",
    "query_words = re.findall(r'\\w+', query)\n",
    "\n",
    "# for each word in the query, get the tfidf value\n",
    "vectorizer_list = []\n",
    "for word in query_words:\n",
    "    if word not in vectorizer.vocabulary_:\n",
    "        continue\n",
    "    j = vectorizer.vocabulary_[word]\n",
    "    vectorizer_list.append(j)\n",
    "# \n",
    "local_tfidf = tfidf[:,vectorizer_list]\n",
    "\n",
    "sum_local_tfidf = np.sum(local_tfidf, axis=1)\n",
    "\n",
    "# get the movie with the highest tfidf\n",
    "m = sum_local_tfidf.argmax()\n",
    "print(sum_local_tfidf.argmax())\n",
    "print(\"tfidf: \", sum_local_tfidf[m])\n",
    "print(df.iloc[sum_local_tfidf.argmax()]['Title'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 5\n",
    "**Objetivo: implementar um índice invertido**\n",
    "\n",
    "Você provavelmente reparou (talvez não tenha reparado, e é tudo bem) que, para fazer a busca, até agora, teve que varrer todos os documentos da sua coleção. Isso provavelmente levaria algum tempo, especialmente quando a coleção começa a aumentar. Para evitar ter que varrer todos os documentos da coleção, podemos implementar uma técnica chamada *índice invertido*. A ideia do índice invertido é usar um dicionário cujas chaves são as palavras do vocabulário e cujo conteúdo é uma lista de documentos que contém essa palavra, possivelmente acompanhados do TFIDF correspondente. Por exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('documento_2', 0.7), ('documento_1', 0.5)]\n"
     ]
    }
   ],
   "source": [
    "indice = { 'palavra_1' : {'documento_1': 0.5, 'documento_2': 0.1}, \n",
    "          'palavra_2' : {'documento_2': 0.6},\n",
    "            'equalization': {'documento_1': 0.5}\n",
    "}\n",
    "\n",
    "def buscar(palavras, indice):\n",
    "    assert type(palavras)==list\n",
    "    resultado = dict()\n",
    "    for p in palavras:\n",
    "        if p in indice.keys():\n",
    "            for documento in indice[p].keys():\n",
    "                if documento not in resultado.keys():\n",
    "                    resultado[documento] = indice[p][documento]\n",
    "                else:\n",
    "                    resultado[documento] += indice[p][documento]\n",
    "    return resultado\n",
    "\n",
    "buscar(['palavra_1', 'palavra_2','equalization'], indice)\n",
    "\n",
    "\n",
    "def n_maiores(res_busca,n):\n",
    "    res = []\n",
    "    for k in res_busca.keys():\n",
    "        res.append((k,res_busca[k]))\n",
    "    res = sorted(res, key=lambda x: x[1], reverse=True)\n",
    "    return res[:n]\n",
    "\n",
    "res = buscar(['palavra_1', 'palavra_2'], indice)\n",
    "\n",
    "print(n_maiores(res,2))\n",
    "\n",
    "def query(query, indice, n):\n",
    "    palavras = re.findall(r'\\w+', query)\n",
    "    res_busca = buscar(palavras, indice)\n",
    "    return n_maiores(res_busca,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('documento_2', 0.7), ('documento_1', 0.5)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query('palavra_1 palavra_2', indice, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Adicione uma nova palavra ao índice e escolha seu TFIDF. Realize uma nova busca e verifique o resultado.\n",
    "1. Escreva uma função que ordena o resultado e retorna apenas `N` documentos mais relevantes para sua busca.\n",
    "1. Incremente sua biblioteca de forma que ela passe a receber uma string como entrada (representando a query) e retorne os `N` documentos mais relevantes (`N` pode ser definido arbitrariamente)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 6\n",
    "**Objetivo: implementar um buscador de filmes**\n",
    "\n",
    "Implemente uma função que recebe como entrada uma query e retorna os títulos e enredos dos 5 filmes mais relevantes para aquela query. Se precisar, use mais parâmetros ou variáveis globais. Teste a sua função e veja se você concorda com os resultados, incluindo se você consegue encontrar seus filmes favoritos e se consegue alguma recomendação relevante a um filme novo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_movies(query : str):\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 7\n",
    "**Objetivo: identificar palavras-chave usando TFIDF**\n",
    "\n",
    "Uma outra aplicação de TFIDF é encontrar palavras-chave, isto é, palavras que diferenciam um documento do restante dos documentos de sua coleção.\n",
    "\n",
    "Incremente seu buscador de forma que, além do título e enredo, ele também escolha as algumas palavras (escolha quantas!) mais relevantes de cada documento e as imprima como keywords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 8\n",
    "**Objetivo: encontrar documentos semelhantes usando TFIDF**\n",
    "\n",
    "Uma maneira de encontrar documentos semelhantes em uma coleção de textos é assumir que o texto do documento é uma query, e então realizar a busca normalmente. O problema disso é que provavelmente teríamos textos muito longos e a query ficaria muito carregada. Para solucionar isso, poderíamos usar apenas as palavras mais relevantes de um documento como query. Implemente uma função que recebe o índice (ou outro identificador único) de um documento de nosso banco de dados e então encontra 5 documentos semelhantes a ele."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
